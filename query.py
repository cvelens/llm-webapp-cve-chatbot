import faiss
import numpy as np
from sentence_transformers import SentenceTransformer, util
import psycopg2
from mistralai import Mistral

# Load the LLM model 
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

# Load FAISS index from the specified path
index = faiss.read_index('/mnt/data/faiss_index.index')

# Connect to the PostgreSQL database
conn = psycopg2.connect(
    dbname="cve",
    user="postgres",
    password="admin",
    host="csye7125-consumer-headless.ns3.svc.cluster.local",
    port="5432"
)

# Create a cursor object
cur = conn.cursor()

# Query to select the JSON data from the specified column
cur.execute("SELECT data FROM cve.cve")

# Fetch all rows from the executed query
rows = cur.fetchall()

# Close the cursor and connection
cur.close()
conn.close()

# Since the data is already a dictionary, just extract it
data = [row[0] for row in rows]

def concatenate_record(record):
    fields = []

    # Ensure 'containers' and 'cna' exist and are not None
    cna = record.get('containers', {}).get('cna', {})

    # Add product, vendor, version, descriptions, etc.
    affected = cna.get('affected', [])
    if affected:  
        for item in affected:
            fields.append(item.get('vendor', ''))
            fields.append(item.get('product', ''))
            versions = item.get('versions', [])
            if versions:  
                fields.extend([v.get('version', '') for v in versions])
    
    descriptions = cna.get('descriptions', [])
    if descriptions:  
        for desc in descriptions:
            fields.append(desc.get('value', ''))
    
    problem_types = cna.get('problemTypes', [])
    if problem_types:  
        for problem in problem_types:
            fields.append(problem['descriptions'][0].get('description', ''))

    if 'cveMetadata' in record:
        fields.append(record['cveMetadata'].get('cveId', ''))
        fields.append(record['cveMetadata'].get('state', ''))
        fields.append(record['cveMetadata'].get('datePublished', ''))
        fields.append(record['cveMetadata'].get('assignerShortName', ''))
    
    # Combine all fields into one string
    combined_text = ' '.join(fields)
    return combined_text

# Prepare the data for indexing
combined_texts = [concatenate_record(record) for record in data]

# Querying the FAISS index
query = "find me the product involving woocommerce"
query_embedding = model.encode(query, convert_to_tensor=False).reshape(1, -1)

# Search for top 5 similar records
D, I = index.search(query_embedding, k=5)

# Prepare the top 5 results
top_records = []
for idx in I[0]:
    top_records.append({
        'record': data[idx],
        'text': combined_texts[idx]
    })

formatted_text = "\n\n".join([f"Record {i+1}:\n{record['text']}" for i, record in enumerate(top_records)])

# Use Mistral API to determine the response
api_key = "Z2rZVSSsC1SufGgBRKHpmHRVRpbDri8D"
model_name = "mistral-large-latest"

client = Mistral(api_key=api_key)

# Create the prompt for Mistral based on the query content
if "all" in query.lower():
    # If "all" is in the query, ask Mistral to return all records in readable format
    prompt = f"Here are 5 records related to the query '{query}':\n\n{formatted_text}\n\nProvide all records in a readable format."
else:
    # Otherwise, ask Mistral to return the most relevant record
    prompt = f"Here are 5 records related to the query '{query}':\n\n{formatted_text}\n\nWhich record is the most relevant? Provide the most relevant record in a readable format."

# Send the request to the Mistral API
chat_response = client.chat.complete(
    model=model_name,
    messages=[
        {
            "role": "user",
            "content": prompt,
        },
    ]
)

# Extract and print the response
response_text = chat_response.choices[0].message.content

print("Response:")
print(response_text)
